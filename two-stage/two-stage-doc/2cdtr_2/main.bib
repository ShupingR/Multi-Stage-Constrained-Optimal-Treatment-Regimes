@book{Forsgren2002,
	abstract = {Interior methods are an omnipresent, conspicuous feature of the constrained optimiza- tion landscape today, but it was not always so. Primarily in the form of barrier methods, interior-point techniques were popular during the 1960s for solving nonlinearly constrained problems. However, their use for linear programming was not even contemplated because of the total dominance of the simplex method. Vague but continuing anxiety about barrier methods eventually led to their abandonment in favor of newly emerging, apparently more efficient alternatives such as augmented Lagrangian and sequential quadratic programming methods. By the early 1980s, barrier methods were almost without exception regarded as a closed chapter in the history of optimization. This picture changed dramatically with Karmarkar's widely publicized announcement in 1984 of a fast polynomial-time interior method for linear programming; in 1985, a formal connection was established between his method and classical barrier methods. Since then, interior methods have advanced so far, so fast, that their influence has transformed both the theory and practice of constrained optimization. This article provides a condensed, se- lective look at classical material and recent research about interior methods for nonlinearly constrained optimization.},
	author = {Forsgren, Anders and Gill, PE and Wright, MH},
	booktitle = {Society for Industrial and Applied Mathematics (SIAM Review)},
	doi = {10.1137/S0036144502414942},
	isbn = {0036144502414},
	issn = {0036-1445},
	keywords = {barrier methods,constrained minimization,interior methods,nonlinear constraints,nonlinear programming,penalty methods,primal-dual methods},
	mendeley-groups = {Current},
	number = {4},
	pages = {525--597},
	title = {{Interior Methods for Nonlinear Optimization}},
	url = {http://epubs.siam.org/doi/abs/10.1137/S0036144502414942},
	volume = {44},
	year = {2002}
}
@article{Rubin2005,
	abstract = {Causal effects are defined as comparisons of potential outcomes under different treatments on a common set of units. Observed values of the potential outcomes are revealed by the assignment mechanism?a probabilistic model for the treatment each unit receives as a function of covariates and potential outcomes. Fisher made tremendous contributions to causal inference through his work on the design of randomized experiments, but the potential outcomes perspective applies to other complex experiments and nonrandomized studies as well. As noted by Kempthorne in his 1976 discussion of Savage's Fisher lecture, Fisher never bridged his work on experimental design and his work on parametric modeling, a bridge that appears nearly automatic with an appropriate view of the potential outcomes framework, where the potential outcomes and covariates are given a Bayesian distribution to complete the model specification. Also, this framework crisply separates scientific inference for causal effects and decisions based on such inference, a distinction evident in Fisher's discussion of tests of significance versus tests in an accept/reject framework. But Fisher never used the potential outcomes framework, originally proposed by Neyman in the context of randomized experiments, and as a result he provided generally flawed advice concerning the use of the analysis of covariance to adjust for posttreatment concomitants in randomized trials.},
	author = {Rubin, Donald B.},
	doi = {10.1198/01621450400000188O},
	isbn = {01621459},
	issn = {0162-1459},
	journal = {Journal of the American Statistical Association},
	keywords = {Analysis fo covariance,Baysian inference,Fieller-Creasy,Fischer,Neyman,Observational studies,Principle stratification,Randomized experiments,Rubin causal model,assignment mechanism,assignment-based causal inference,direct causal effects},
	mendeley-groups = {Current},
	pages = {322--331},
	title = {{Causal inference using potential outcomes: Design, modeling, decisions}},
	volume = {100},
	year = {2005}
}
@book{Pagan1999,
address = {Cambridge },
author = {Pagan, A. R. and Ullah, Aman.},
isbn = {seq001|0521355648},
pages = {424},
publisher = {Cambridge University Press,},
series = {Themes in modern econometrics},
title = {{Nonparametric econometrics / Adrian Pagan, Aman Ullah.}},
url = {http://catalog.lib.ncsu.edu/record/NCSU1253883},
year = {1999}
}
@book{Li2011,
abstract = {Until now, students and researchers in nonparametric and semiparametric statistics and econometrics have had to turn to the latest journal articles to keep pace with these emerging methods of economic analysis. Nonparametric Econometrics fills a major gap by gathering together the most up-to-date theory and techniques and presenting them in a remarkably straightforward and accessible format. The empirical tests, data, and exercises included in this textbook help make it the ideal introduction for graduate students and an indispensable resource for researchers. Nonparametric and semiparametric methods have attracted a great deal of attention from statisticians in recent decades. While the majority of existing books on the subject operate from the presumption that the underlying data is strictly continuous in nature, more often than not social scientists deal with categorical data--nominal and ordinal--in applied settings. The conventional nonparametric approach to dealing with the presence of discrete variables is acknowledged to be unsatisfactory. This book is tailored to the needs of applied econometricians and social scientists. Qi Li and Jeffrey Racine emphasize nonparametric techniques suited to the rich array of data types--continuous, nominal, and ordinal--within one coherent framework. They also emphasize the properties of nonparametric estimators in the presence of potentially irrelevant variables.  Nonparametric Econometrics covers all the material necessary to understand and apply nonparametric methods for real-world problems.},
author = {Li, Qi and Racine, Jeffrey Scott},
isbn = {1400841062},
pages = {768},
publisher = {Princeton University Press},
title = {{Nonparametric Econometrics: Theory and Practice}},
url = {https://books.google.com/books?id=Zsa7ofamTIUC{\&}pgis=1},
year = {2011}
}
@article{Blackwell1982,
abstract = {The Cox regression model for censored survival data specifies that covariates have a proportional effect on the hazard function of the life-time distribution of an individual. In this paper we discuss how this model can be extended to a model where covariate processes have a proportional effect on the intensity process of a multivariate counting process. This permits a statistical regression analysis of the intensity of a recurrent event allowing for complicated censoring patterns and time dependent covariates. Furthermore, this formulation gives rise to proofs with very simple structure using martingale techniques for the asymptotic properties of the estimators from such a model. Finally an example of a statistical analysis is included.},
author = {Blackwell, D},
doi = {10.1214/aos/1176348654},
file = {:Users/shuping.ruan/Dropbox/constrained-optimal-regime-1/Citation/Blackwell{\_}1982{\_}Institute of Mathematical Statistics is collaborating with JSTOR to digitize, preserve, and extend access to The Annals.pdf:pdf},
issn = {00905364},
journal = {Statistics},
number = {2},
pages = {1100--1120},
title = {{Institute of Mathematical Statistics is collaborating with JSTOR to digitize, preserve, and extend access to The Annals of Statistics. {\textregistered} www.jstor.org}},
url = {http://projecteuclid.org/euclid.aos/1176345976},
volume = {10},
year = {1982}
}
@article{Silverman1978a,
abstract = {The estimation uniform of a density consistency is considered. Uniform consistency are studied. For suitable kernels shown that the conditions h - strong conditions consistency and its derivatives properties and uniformly of the density size and h is the "window width." Under certain are found on the density rate of strong width which are necessary and sufficient of the estimate of the density and weak consistency estimate, by the kernel method over the whole real line it is continuous conditions densities 0 and (nh)- log n - 0 are sufficient where n is the sample on the kernel, for and on the behavior of the window for weak and strong uniform derivatives. Theorems on the are also proved.},
author = {Silverman, Bernard W},
journal = {The Annals of Statistics},
number = {1},
pages = {177--184},
title = {{Weak and Strong Uniform Consistency of the Kernel Estimate of a Density and its Derivatives}},
volume = {6},
year = {1978}
}
@article{Statistics2016,
author = {Statistics, Mathematical},
file = {:Users/shuping.ruan/Dropbox/constrained-optimal-regime-1/Citation/Statistics{\_}2016{\_}On Estimation of a Probability Density Function and Mode Author ( s ) Emanuel Parzen Source The Annals of Mathematical.pdf:pdf},
number = {3},
pages = {1065--1076},
title = {{On Estimation of a Probability Density Function and Mode Author ( s ): Emanuel Parzen Source : The Annals of Mathematical Statistics , Vol . 33 , No . 3 ( Sep ., 1962 ), pp . 1065-1076 Published by : Institute of Mathematical Statistics Stable URL : http://www.jstor.org/stable/2237880 REFERENCES Linked references are available on JSTOR for this article : You may need to log in to JSTOR to access the linked references .}},
volume = {33},
year = {2016}
}
@article{Statistics2009,
author = {Statistics, Mathematical},
file = {:Users/shuping.ruan/Dropbox/constrained-optimal-regime-1/Citation/Statistics{\_}2009{\_}The L1 Convergence of Kernel Density Estimates Author ( s ) L . P . Devroye and T . J . Wagner Source The Annals of Sta.pdf:pdf},
number = {5},
pages = {1136--1139},
title = {{The L1 Convergence of Kernel Density Estimates Author ( s ): L . P . Devroye and T . J . Wagner Source : The Annals of Statistics , Vol . 7 , No . 5 ( Sep ., 1979 ), pp . 1136-1139 Published by : Institute of Mathematical Statistics Stable URL : http://ww}},
volume = {7},
year = {2009}
}
@article{Gine2002,
abstract = {Let fn denote the usual kernel density estimator in several dimensions. It is shown that if {\{}an{\}} is a regular band sequence, K is a bounded square integrable kernel of several variables, satisfying some additional mild conditions ((K1) below), and if the data consist of an i.i.d. sample from a distribution possessing a bounded density f with respect to Lebesgue measure on Rd, then. for some absolute constant C that depends only on d. With some additional but still weak conditions, it is proved that the above sequence of normalized suprema converges a.s. to 2d f ∞ ∫ K2(x) dx. Convergence of the moment generating functions is also proved. Neither of these results require f to be strictly positive. These results improve upon, and extend to several dimensions, results by Silverman [13] for univariate densities. {\textcopyright} 2002 {\'{E}}ditions scientifiques et m{\'{e}}dicales Elsevier SAS.},
author = {Gin{\'{e}}, Evarist and Guillou, Armelle},
doi = {10.1016/S0246-0203(02)01128-7},
file = {:Users/shuping.ruan/Dropbox/constrained-optimal-regime-1/Citation/Gin{\'{e}}, Guillou{\_}2002{\_}Rates of strong uniform consistency for multivariate kernel density estimators.pdf:pdf},
issn = {02460203},
journal = {Annales de l'institut Henri Poincare (B) Probability and Statistics},
keywords = {Kernel density estimators,Non-parametric density estimation,Uniform almost sure rates},
number = {6},
pages = {907--921},
title = {{Rates of strong uniform consistency for multivariate kernel density estimators}},
volume = {38},
year = {2002}
}
@article{Devroye1986,
author = {Devroye, L. and Penrod, C.S.},
file = {:Users/shuping.ruan/Dropbox/constrained-optimal-regime-1/Citation/Devroye, Penrod{\_}1986{\_}The strong uniform convergence of multivariate variable kernel estimates.pdf:pdf},
journal = {Canadian Journal of Statistics},
keywords = {62h99,ams 1980 subject classifications,and phrases,breiman,consistency,density estimation,estimate,kernel,primary 60f15,s estimate,secondary 62g99,strong convergence},
number = {3},
pages = {211--220},
title = {{The strong uniform convergence of multivariate variable kernel estimates}},
url = {http://onlinelibrary.wiley.com/doi/10.2307/3314798/abstract},
volume = {14},
year = {1986}
}
@article{Theo,
author = {Cacoullos, Theophilos},
file = {:Users/shuping.ruan/Dropbox/constrained-optimal-regime-1/Citation/Cacoullos{\_}1964{\_}Estimation of a Multivariate Density.pdf:pdf},
isbn = {0277538718},
pages = {251--255},
title = {{Estimation of a Multivariate Density}},
year = {1964}
}
@article{Scott2015,
abstract = {Clarifies modern data analysis through nonparametric density estimation for a complete working knowledge of the theory and methods Featuring a thoroughly revised presentation, "Multivariate Density Estimation: Theory, Practice, and Visualization, Second Edition" maintains an intuitive approach to the underlying methodology and supporting theory of density estimation. Including new material and updated research in each chapter, the "Second Edition" presents additional clarification of theoretical opportunities, new algorithms, and up-to-date coverage of the unique challenges presented in the field of data analysis. The new edition focuses on the various density estimation techniques and methods that can be used in the field of big data. Defining optimal nonparametric estimators, the "Second Edition" demonstrates the density estimation tools to use when dealing with various multivariate structures in univariate, bivariate, trivariate, and quadrivariate data analysis. Continuing to illustrate the major concepts in the context of the classical histogram, "Multivariate Density Estimation: Theory, Practice, and Visualization, Second Edition" features: Over 150 updated figures to clarify theoretical results and to show analyses of real data sets An updated presentation of graphic visualization using computer software such as R A clear discussion of selections of important research during the past decade, including mixture estimation, robust parametric modeling algorithms, and clustering Over 130 problems to help readers reinforce the main concepts and ideas presented Boxed theorems and results allowing easy identification of crucial ideas " Multivariate Density Estimation: Theory, Practice, and Visualization, Second Edition" is an ideal reference for theoretical and applied statisticians, practicing engineers, as well as all readers interested in the theoretical aspects of nonparametric estimation and the application of these methods to multivariate data. The "Second Edition" is also a useful as a textbook for introductory courses in kernel statistics, smoothing, advanced computational statistics, and general forms of statistical distributions. "David W. Scott, PhD, " is Noah Harding Professor in the Department of Statistics at Rice University. The author of over 100 published articles, papers, and book chapters, Dr. Scott is also Fellow of the American Statistical Association (ASA) and the Institute of Mathematical Statistics. He is recipient of the ASA Founder's Award and the Army Wilks Award. His research interests include computational statistics, data visualization, and density estimation. Dr. Scott is also Coeditor of "Wiley Interdisciplinary Reviews: Computational Statistics" and previous Editor of the "Journal of Computational and Graphical Statistics."},
author = {Scott, David W.},
file = {:Users/shuping.ruan/Dropbox/constrained-optimal-regime-1/Citation/Scott{\_}2015{\_}Multivariate Density estimation Theory, Practice, and Visualization.pdf:pdf},
isbn = {1118575539},
pages = {360},
title = {{Multivariate Density estimation : Theory, Practice, and Visualization}},
volume = {1},
year = {2015}
}
@misc{Devroye1980,
author = {Devroye, Luc P. and Wagner, T. J.},
booktitle = {Multivariate analysis},
file = {:Users/shuping.ruan/Dropbox/constrained-optimal-regime-1/Citation/Devroye, Wagner{\_}1980{\_}The Strong Uniform Consistency of Kernel Density Estimates.pdf:pdf},
pages = {59--77},
title = {{The Strong Uniform Consistency of Kernel Density Estimates}},
year = {1980}
}
@article{If2010,
author = {If, Terence Tao},
file = {:Users/shuping.ruan/Dropbox/constrained-optimal-regime-1/Citation/If{\_}2010{\_}245A , Notes 4 Modes of convergence.pdf:pdf},
pages = {1--20},
title = {{245A , Notes 4 : Modes of convergence}},
year = {2010}
}
@article{There2009,
author = {There, Definition and Big, Terminology and Analysis, Asymptotic},
file = {:Users/shuping.ruan/Dropbox/constrained-optimal-regime-1/Citation/There, Big, Analysis{\_}2009{\_}Asymptotic notations 2.1.pdf:pdf},
journal = {Asymptotic Analysis},
pages = {9--31},
title = {{Asymptotic notations 2.1}},
year = {2009}
}
@misc{Rosenblatt1956,
abstract = {This note discusses some aspects of the estimation of the density function of a univariate probability distribution. All estimates of the density function satisfying relatively mild conditions are shown to be biased. The asymptotic mean square error of a particular class of estimates is evaluated.},
author = {Rosenblatt, Murray},
booktitle = {The Annals of Mathematical Statistics},
doi = {10.1214/aoms/1177728190},
file = {:Users/shuping.ruan/Dropbox/constrained-optimal-regime-1/Citation/Rosenblatt{\_}1956{\_}Remarks on Some Nonparametric Estimates of a Density Function.pdf:pdf},
isbn = {00034851},
issn = {0003-4851},
pages = {832--837},
title = {{Remarks on Some Nonparametric Estimates of a Density Function}},
volume = {27},
year = {1956}
}
@article{Lindsay1995,
	abstract = {PROBABILITY AND MEASURE Third Edition Now in its new third edition, Probability and Measure offers advanced students, scientists, and engineers an integrated introduction to measure theory and probability. Retaining the unique approach of the previous editions, this text interweaves material on probability and measure, so that probability problems generate an interest in measure theory and measure theory is then developed and applied to probability. Probability and Measure provides thorough coverage of probability, measure, integration, random variables and expected values, convergence of distributions, derivatives and conditional probability, and stochastic processes. The Third Edition features an improved treatment of Brownian motion and the replacement of queuing theory with ergodic theory. Like the previous editions, this new edition will be well received by students of mathematics, statistics, economics, and a wide variety of disciplines that require a solid understanding of probability theory.},
	author = {Billingsley, Patrick},
	doi = {10.1016/0167-9473(95)90197-3},
	file = {:Users/shuping.ruan/Dropbox/constrained-optimal-regime-1/Citation/Billingsley{\_}1995{\_}Probability {\&} Measure.pdf:pdf},
	isbn = {0471007102},
	issn = {01679473},
	mendeley-groups = {One Stage Proof},
	pages = {362},
	title = {{Probability {\&} Measure}},
	year = {1995}
}
@article{Hunter2014,
	author = {Hunter, David R},
	file = {:Users/shuping.ruan/Dropbox/constrained-optimal-regime-1/Citation/Hunter{\_}2014{\_}Notes for a graduate-level course in asymptotics for statisticians.pdf:pdf},
	mendeley-groups = {One Stage Proof},
	pages = {97},
	title = {{Notes for a graduate-level course in asymptotics for statisticians}},
	year = {2014}
}
@book{Nocedal1999,
	abstract = {Despite application of cryogen spray (CS) precooling, customary treatment of port wine stain (PWS) birthmarks with a single laser pulse does not result in complete lesion blanching for a majority of patients. One obvious reason is nonselective absorption by epidermal melanin, which limits the maximal safe radiant exposure. Another possible reason for treatment failure is screening of laser light within large PWS vessels, which prevents uniform heating of the entire vessel lumen. Our aim is to identify the parameters of sequential CS cooling and laser irradiation that will allow optimal photocoagulation of various PWS blood vessels with minimal risk of epidermal thermal damage.},
	author = {Nocedal, J and Wright, S J},
	booktitle = {Analysis},
	chapter = {5},
	doi = {10.1002/lsm.21040},
	editor = {Glynn, Peter and Robinson, Stephen M},
	isbn = {0387987932},
	issn = {10969101},
	number = {2},
	pages = {164--75},
	pmid = {21384397},
	publisher = {Springer},
	series = {Springer Series in Operations Research},
	title = {{Numerical Optimization}},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21643320},
	volume = {43},
	year = {2006}
}
@book{fiacco,
	author = {Anthony V. Fiacco, Garth P. McCormick},
	title = {Nonlinear Programming: Sequential Unconstrained Minimization Techniques},
}
@article{Gill2001,
	abstract = {We extend Robins' theory of causal inference for complex longitudinal data to the case of continuously varying as opposed to discrete covariates and treatments. In particular we establish versions of the key results of the discrete theory: the g-computation formula and a collection of powerful characterizations of the g-null hypothesis of no treatment effect. This is accomplished under natural continuity hypotheses concerning the conditional distributions of the outcome variable and of the covariates given the past. We also show that our assumptions concerning counterfactual variables place no restriction on the joint distribution of the observed variables: thus in a precise sense, these assumptions are "for free," or if you prefer, harmless. CR - Copyright {\&}{\#}169; 2001 Institute of Mathematical Statistics},
	author = {Gill, Richard D. and Robins, James M.},
	doi = {10.1214/aos/1015345962},
	isbn = {0090-5364},
	issn = {00905364},
	journal = {Annals of Statistics},
	keywords = {Causality,Counterfactuals,Longitudinal data,Observational studies},
	number = {6},
	pages = {1785--1811},
	title = {{Causal inference for complex longitudinal data: The continuous case}},
	volume = {29},
	year = {2001}
}

