% asymptotics for estimated indexing parm
\documentclass[../main.tex]{subfiles}
\begin{document}
\textbf{Limiting distribution of $\wh{\bs{\tau}}$}\\
Before we derive the limiting distribution of the estimator $\wh{\bs{\tau}}_{\kappa,\mu}$, we need to examine, for any fixed value of $\bs{\tau}: \bs{\tau}_1^\itl\bs{\tau}_1 = 1$ and $\bs{\tau}_2^\itl\bs{\tau}_2 = 1$, the limiting distribution of $\nabla \wh{\mb{E}} Y_n(\bs{\tau})$.
\begin{flalign*}
\nabla \wh{\mb{E}} Y_n(\bs{\tau}) = &\pard[\bs{\tau}] \int y \,d \wh{F}_{Y_n(\bs{\tau})}(y) \\
= &\pard[\bs{\tau}] \int y \,d \lt[ \mean[n] \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i}) \rt] \\
= & \mean[n] \pard[\bs{\tau}] \int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i}) 
\end{flalign*}
%\begin{gather}
%\begin{flalign*}
%\nabla_{\bs{\tau}}\wh{\mathbb{E}}\lt\{ \text{sgn}\lt(\bs{X}^{\intercal}\bs{\tau}\rt)\bs{X}_1^{\intercal}\bs{\beta}_{Y1}\rt\} =\nabla_{\bs{\tau}}\lt[\frac{1}{n}\sum_{i=1}^{n}\bs{X}_{i,1}^{\intercal}\bs{\beta}_{Y1}\lt\{ 1-2K\lt(-\frac{\bs{X}^{\intercal}_{i}\bs{\tau}}{h}\rt)\rt\} \rt]=\frac{1}{n}\sum_{i=1}^{n}\frac{2\bs{X}_{i,1}^{\intercal}\bs{\beta}_{Y1}}{h}k\lt(-\frac{\bs{X}_{i}^{\intercal}\bs{\tau}}{h}\rt)\bs{X}_{i}.
%\end{flalign*}
%\end{gather}

\begin{lemma}
In addition to the assumptions in corollary 1, we also suppose the following conditions hold.
\begin{enumerate}
\item $\bs{H}_1^{\intercal}\bs{\tau}_1$  and $\bs{H}_2^{\intercal}\bs{\tau}_2$ are both bounded away from 0.
\item $\forall \bs{a} \in \mathbb{R}^p$,$\exists \delta > 0$ ,such that 
\begin{enumerate}
\item $\mathbb{E}\lt|\bs{a}^\itl\pard[\bs{\tau}] \int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})\rt|^{2+\delta} < \infty$ 
\item $ \lt\{\bs{\bs{a}^{\intercal}}V\lt[\pard[\bs{\tau}] \int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})\rt]\bs{a} \rt\}^{1+\frac{\delta}{2}}< \infty$.
\end{enumerate}
\end{enumerate} 
Then, we have, for any fixed $\bs{\tau}$ and $\bs{\beta}_{Y1}$,
\begin{gather}
\begin{flalign*}
\sqrt{n}\lt[\nabla \wh{\mb{E}} Y_n(\bs{\tau})  -\mathbb{E}\lt(\nabla \wh{\mb{E}} Y_n(\bs{\tau})\rt)\rt]\overset{d}{\to}\mathcal{N}\lt(0,AV\lt[\pard[\bs{\tau}] \int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i}) \rt]\rt)
\end{flalign*}
\end{gather}
\end{lemma}

The proof of this is similar to the proof of Lemma 1 in the one-stage problem.
%\subsection{Limiting distribution of $\nabla_{\bs{\tau}}\wh{\mathbb{E}}\lt\{ \text{sgn}\lt(\bs{X}^{\intercal}\bs{\tau}\rt)\bs{X}_1^{\intercal}\bs{\beta}_{Y1}\rt\} $}

%Comment: Goal is to prove the derivative above is asymptotically normal.
%Considering that it includes sample size $n$ in $h$, and it is multivariate.
%Try Lyapunov condition and cramer-wold theorem first.
%
%The sequences here are a triangular array, and are iid for each $n$.
%
%$k$ is the kernel of our choice, gaussian kernel.

\begin{proof}
For any  $\bs{a} \in \mathbb{R}^p$, we let $W_{ni} = \bs{a}^\itl \pard[\bs{\tau}]\int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})$. For each value of $n$, $w_{n1},w_{n2},\cdots,w_{nn}$ are i.i.d, and functions of the sample size $n$. This is because that $\bs{X}_{i}$ are assumed to be i.i.d., and $h$ is a function of sample
size $n$. Then, we have
\begin{gather*}
\mu_{n}:=\mathbb{E}W_{ni}=\mathbb{E}\lt[\bs{a}^\itl \pard[\bs{\tau}]\int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})\rt],
\end{gather*}
and 
\begin{gather*}
\sigma_{n}^{2}:=V(W_{ni})=\bs{a}^\itl V\lt[\pard[\bs{\tau}]\int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i}) \rt]\bs{a}
\end{gather*}

%?????????????????????????????????????????????????????????? \\
%??? Delta method and Taylor expansion for approximation ??? \\
%?????????????????????????????????????????????????????????? \\
We let $G_{ni}=W_{ni}-\mu_{\ensuremath{n}}$, and $T_{n}=\sum_{i=1}^{n}G_{ni}$. Also, we let $s_{n}^{2}=V(T_{n})=\sum_{i=1}^{n}V(G_{ni})=\sum_{i=1}^{n}\sigma_{n}^{2}=n\sigma_{n}^{2}$, where the second equality is because of independence, and the last equality is due to identicalness. Therefore, $\sfrac{T_{n}}{s_{n}}$ has mean 0, and variance 1.  If we can show $G_{ni}$ satisfying the Lyapunov condition, then
we have

$$\frac{T_{n}}{s_{n}}\overset{d}{\to}\mathcal{N}(0,1),\text{ as } n \to \infty$$,



Now, we check the Lyapunov condition, that is, ~\cite{Lindsay1995,Hunter2014}
\begin{gather*}
\exists\delta>0, \text{ such that } \frac{1}{s_{n}^{2+\delta}}\sum_{i=1}^{n}\mathbb{E}\mid G_{n,i}\mid^{2+\delta}\to0, \text{ as } n\to0. 
\end{gather*}
We define, for any $\bs{a}$, 
\begin{gather*}
C_1 \triangleq \mathbb{E}\lt|G_{ni}\rt|^{2+\delta}=\mathbb{E}\lt|W_{ni}-\mu_{\ensuremath{n}}\rt|^{2+\delta}=\mathbb{E}\lt|\bs{a}^\itl \pard[\bs{\tau}]\int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})-\mu_{n}\rt|^{2+\delta},
\end{gather*}
and 
\begin{gather*}
C_2 \triangleq s_{n}^{2+\delta}=n^{1+\frac{\delta}{2}}\sigma_{n}^{2+\delta}=n^{1+\frac{\delta}{2}}\lt\{ \bs{a}^\itl  V \lt[ \pard[\bs{\tau}]\int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i}) \rt] \bs{a} \rt\} ^{1+\frac{\delta}{2}}.
\end{gather*}
Then, we have
\begin{flalign*}
&\frac{1}{s_{n}^{2+\delta}}\sum_{i=1}^{n}\mathbb{E}\mid G_{n,i}\mid^{2+\delta}\\
=&\frac{\mathbb{E}\lt|\bs{a}^\itl \pard[\bs{\tau}]\int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})-\mu_{n}\rt|^{2+\delta}}{n^{\frac{\delta}{2}}\lt\{ \bs{a}^{\intercal}V\lt[\pard[\bs{\tau}]\int y \,d  \wh{F}_{Y_n(\bs{\tau})}\lt(y | \bs{H}_{1,i} = \bs{h}_{1,i}\rt) \rt]\bs{a}\rt\} ^{1+\frac{\delta}{2}}} \\
=&\frac{C_{1}}{n^{\frac{\delta}{2}}C_{2}}.
\end{flalign*}

As long as $\delta>0$, for finite $C_1$ and finite $C_2$, we have $\sfrac{C_{1}}{n^{\frac{\delta}{2}}C_{2}}\to0$,
as $n\to\infty$. This means that the Lyapunov condition is satisfied, if $\mathbb{E}\lt|G_{ni}\rt|^{2+\delta}$ and $s_{n}^{2+\delta}$ are finite. Then,  by Lyapunov Central Limit Theorem, we have
\begin{gather*}
\frac{T_{n}}{s_{n}}\overset{d}{\to}\mathcal{N}(0,1).
\end{gather*}

As this hold for any arbitary non-random vector $\bs{a}\in \mathbb{R}^p$, we have, by Cramer-Wold Theorem, that
\begin{gather*}
\sqrt{n}\lt[\mean[n] \pard[\bs{\tau}]\int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i}) -\mathbb{E}\lt\{ \pard[\bs{\tau}]\int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})\rt\}\rt]\overset{d}{\to}\mathcal{N}\lt(0,V\lt[\pard[\bs{\tau}]\int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})\rt]\rt),
\end{gather*}
as $n \to \infty$. We denote $\bs{L}_{ni}= \pard[\bs{\tau}]\int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})$,
then this is written as
\begin{gather*}
\sqrt{n}\lt[\frac{1}{n}\sum_{i=1}^{n}\bs{L}_{ni}-\mathbb{E}\bs{L}_{n1}\rt]\overset{d}{\to}\mathcal{N}\lt(0,V\lt[\bs{L}_{n1}\rt]\rt).
\end{gather*}
Then, we have
\begin{gather*}
\frac{1/n\sum_{i=1}^{n}\bs{L}_{ni}-\mathbb{E}\bs{L}_{n1}}{[V(\bs{L}_{n1})/n]^{1/2}}\frac{[V(\bs{L}_{n1})/n]^{1/2}}{\lt[AV(\bs{L}_{n1})/n\rt]^{1/2}}\overset{d}{\to}\mathcal{N}(0,1).
\end{gather*}
As  $n \to \infty$, 
\begin{gather*}
\frac{V(\bs{L}_{n1})^{1/2}}{AV(\bs{L}_{n1})^{1/2}}\to1,
\end{gather*}
then we have
\begin{gather*}
\frac{1/n\sum_{i=1}^{n}\bs{L}_{ni}-\mathbb{E}\bs{L}_{n1}}{[AV(\bs{L}_{n1})/n]^{1/2}}\overset{d}{\to}\mathcal{N}(0,1),
\end{gather*}
i.e.,
\begin{gather*}
\sqrt{n}\lt[1/n\sum_{i=1}^{n}\bs{L}_{ni}-\mathbb{E}\bs{L}_{n1}\rt]\overset{d}{\to}N\lt(0,AV(\bs{L}_{n1})\rt).
\end{gather*}
As $\frac{1}{n}\sum_{i=1}^{n}\bs{L}_{ni} =\mean[n] \pard[\bs{\tau}]\int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i}) = \nabla \wh{\mb{E}} Y_n(\bs{\tau})$, we have
\begin{gather}
\begin{flalign*}
\sqrt{n}\lt[\nabla \wh{\mb{E}} Y_n(\bs{\tau})  -\mathbb{E}\lt\{\nabla \wh{\mb{E}} Y_n(\bs{\tau})\rt\}\rt]\overset{d}{\to}\mathcal{N}\lt(0,AV\lt[\pard[\bs{\tau}] \int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i}) \rt]\rt)
\end{flalign*}
\end{gather}
\end{proof}
Assume $\wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})$, the following lemma shows that the estimations do not effect the limiting distribution obtained above.
\begin{corollary}
Suppose all the assumptions in Lemma 3  hold, and $\wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})$ is a consistent estimator of ${F}_{Y^*(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})$. Then, we have
\begin{gather}
\begin{flalign*}
\sqrt{n}\lt[\nabla \wh{\mb{E}} Y_n(\bs{\tau})  - \nabla \mb{E}Y^*_n(\bs{\tau})\rt]\overset{d}{\to}\mathcal{N}\lt(0,AV\lt[\pard[\bs{\tau}] \int y \,d  F_{Y^*(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i}) \rt]\rt)
\end{flalign*}
\end{gather}
\end{corollary}
\begin{proof}
We write
\begin{gather}
\begin{flalign*}
& \nabla \wh{\mb{E}} Y_n(\bs{\tau})  - \nabla \mb{E}Y^*(\bs{\tau}) \\
= & \nabla \wh{\mb{E}} Y_n(\bs{\tau})  - \mb{E}\lt\{ \nabla \wh{\mb{E}}Y_n(\bs{\tau}) \rt\}  + \mb{E}\lt\{ \nabla \wh{\mb{E}}Y_n(\bs{\tau}) \rt\}\ - \nabla \mb{E}Y^*(\bs{\tau}),
\end{flalign*}
\end{gather}
where $ \mb{E}\lt\{ \nabla \wh{\mb{E}}Y_n(\bs{\tau}) \rt\}\ - \nabla \mb{E}Y^*(\bs{\tau}) =  \mb{E}\lt\{\pard[\bs{\tau}]\int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})\rt\}  - \mb{E} \pard[\bs{\tau}]\int y \,d  F_{Y^*x(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i}) = o_p(1)$ is due to the consistency of $\wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})$ and dominated convergence theorem.\\
By lemma 1, we have
\begin{gather}
\begin{flalign*}
\sqrt{n}\lt[\nabla \wh{\mb{E}} Y_n(\bs{\tau})  -\mathbb{E}\lt\{\nabla \wh{\mb{E}} Y_n(\bs{\tau})\rt\}\rt]\overset{d}{\to}\mathcal{N}\lt(0,AV\lt[\pard[\bs{\tau}] \int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i}) \rt]\rt)
\end{flalign*}
\end{gather}

As $\wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})$ is consistent, we have
\begin{gather*}
\frac{AV\lt[\pard[\bs{\tau}] \int y \,d  \wh{F}_{Y_n(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i}) \rt]}{AV\lt[\pard[\bs{\tau}] \int y \,d  F_{Y^*(\bs{\tau})}(y | \bs{H}_{1,i} = \bs{h}_{1,i}) \rt]} \overset{p}{\to} 1.
\end{gather*}
Then, we have
\begin{gather}
\begin{flalign*}
\sqrt{n}\lt[\nabla \wh{\mb{E}} Y_n(\bs{\tau})  - \nabla \mb{E}Y^*(\bs{\tau})\rt]\overset{d}{\to}\mathcal{N}\lt(0,AV\lt[\pard[\bs{\tau}] \int y \,d  F_{Y^*_n(\bs{\tau})}\lt(y | \bs{H}_{1,i} = \bs{h}_{1,i}\rt) \rt]\rt)
\end{flalign*}
\end{gather}
\end{proof}		


\textbf{Limiting distribution of $\wh{\bs{\tau}}_{\kappa,\mu}$}\\
Now, we investigate the limiting distribution of $\wh{\bs{\tau}}_{\kappa,\mu}$.

\begin{theorem}
Suppose all the assumptions above hold. Then we have, as $n\to \infty$
\begin{flalign*}
\sqrt{n}(\wh{\bs{\tau}}_{\kappa,\mu} - \bs{\tau}_{\kappa,\mu}^*) \overset{d}{\to} \mathcal{N}\lt(\bs{0}, \bs{\Sigma}^* \rt),
\end{flalign*}
where $\bs{\Sigma}^* = \bs{D}^{*-1}\bs{C}^{*}\bs{D}^{*-1}$, 
\begin{flalign*}
\bs{C}^* :=
AV\lt[\pard[\bs{\tau}] \int y \,d F_{Y^*(\bs{\tau})}(y | \bs{H}_{1} = \bs{h}_{1}) \rt],
\end{flalign*}
and
\begin{gather*}                 
\begin{flalign*}
\bs{D}^*:= &\nabla^2 \mb{E} Y^*(\bs{\tau}^*_{\kappa,\mu}) - \mu \frac{\nabla^2 \mb{E} Z^*(\bs{\tau}^*_{\kappa,\mu}) \lt[ \kappa - \mb{E} Z^*(\bs{\tau}^*_{\kappa,\mu}) \rt] + \{ \nabla \mb{E} Z^*(\bs{\tau}^*_{\kappa,\mu}) \}^2}{  \lt\{\kappa - \mb{E} Z^*(\bs{\tau}^*_{\kappa,\mu}) \rt\}^2} \\
= & \nabla^2 {S}^* (\bs{\tau}_{\kappa,\mu}^*, \mu).
\end{flalign*}
\end{gather*}
\end{theorem}
\begin{proof}

Taylor expansion, for each $\mu$ 
$$\nabla\wh{S}(\bs{\tau}^*_{\kappa,\mu},\mu) = \nabla\wh{S}(\wh{\bs{\tau}}_{\kappa,\mu},\mu) - \nabla^2\wh{S}(\tilde{\bs{\tau}}_{\kappa,\mu}, \mu) (\wh{\bs{\tau}}_{\kappa,\mu} - \bs{\tau}^*_{\kappa,\mu} ),$$ 
where $\tilde{\bs{\tau}}_{\kappa,\mu}$ is a vector in between $\wh{\bs{\tau}}_{\kappa,\mu}$ and $\bs{\tau}^*_{\kappa,\mu}$.
As $\wh{\bs{\tau}}_{\kappa}(\mu)$ is the maximizer of $\wh{S}(\bs{\tau}, \mu)$, it satisfies the first order conditions such that $\nabla\wh{S}(\wh{\bs{\tau}}_{\kappa,\mu},\mu) = 0$. Then,
\begin{flalign*}
& \sqrt{n}\nabla\wh{S}(\bs{\tau}^*_{\kappa,\mu},\mu) =  -\sqrt{n} \nabla^2\wh{S}(\tilde{\bs{\tau}}_{\kappa,\mu},\mu ) (\wh{\bs{\tau}}_{\kappa,\mu} - \bs{\tau}^*_{\kappa,\mu} )\\
& \nabla\wh{S}(\bs{\tau}^*_{\kappa,\mu},\mu) = \nabla \wh{\mb{E}} Y_n(\bs{\tau}^*_{\kappa,\mu}) - \mu \frac{\nabla \wh{\mb{E}} Z_n(\bs{\tau}^*_{\kappa,\mu})}{  \kappa - \wh{\mb{E}} Z_n(\bs{\tau}^*_{\kappa,\mu}) } + + \frac{2}{\mu}\,(\bs{\tau}_{\kappa,\mu}^{*\intercal}\bs{\tau}^*_{\kappa,\mu}-1)\bs{\tau}^*_{\kappa,\mu}, 
\txt{where }\bs{\tau}_{\kappa,\mu}^{*\itl}\bs{\tau}^*_{\kappa,\mu}-1 = 0.\\
& \nabla^2\wh{S}(\bs{\tau}^*_{\kappa,\mu}, \mu) = \nabla^2 \wh{\mb{E}} Y_n(\bs{\tau}^*_{\kappa,\mu}) - \mu \frac{\nabla^2 \wh{\mb{E}} Z_n(\bs{\tau}^*_{\kappa,\mu}) \lt[ \kappa - \wh{\mb{E}} Z_n(\bs{\tau}^*_{\kappa,\mu}) \rt] + \{ \nabla \wh{\mb{E}} Z_n(\bs{\tau}^*_{\kappa,\mu}) \}^2}{  \lt\{\kappa - \wh{\mb{E}} Z_n(\bs{\tau}^*_{\kappa,\mu}) \rt\}^2} 
\end{flalign*}
Then, we have 
\begin{flalign*}
\nabla\wh{S}(\bs{\tau}^*_{\kappa,\mu},\mu) = \nabla \wh{\mb{E}} Y_n(\bs{\tau}^*_{\kappa,\mu}) - \mu \frac{\nabla \wh{\mb{E}} Z_n(\bs{\tau}^*_{\kappa,\mu})}{  \kappa - \wh{\mb{E}} Z_n(\bs{\tau}^*_{\kappa,\mu}) },
\end{flalign*}

%As the left hand side is asymptotically normal with mean $\bs{0}$ and 
By Lemma 3, we have  the first term on the right hand side as
\begin{gather}
\begin{flalign*}
\nabla \wh{\mb{E}} Y_n(\bs{\tau})  \overset{d}{\to}\mathcal{N}\lt\{\nabla \mb{E}Y^*(\bs{\tau}),\frac{1}{n}AV\lt[\pard[\bs{\tau}] \int y \,d F_{Y^*(\bs{\tau})}(y | \bs{H}_{1} = \bs{h}_{1}) \rt]\rt\}
\end{flalign*}
\end{gather}
For the second term on the right hand side, we also have that 
\begin{gather*}
\mu \frac{\nabla \wh{\mb{E}} Z_n(\bs{\tau}^*_{\kappa,\mu})}{  \kappa - \wh{\mb{E}} Z_n(\bs{\tau}^*_{\kappa,\mu}) } \overset{p}{\to} \mu \frac{\nabla \mb{E} Z(\bs{\tau}^*_{\kappa,\mu})}{  \kappa - \mb{E} Z(\bs{\tau}^*_{\kappa,\mu}) },,
\end{gather*}
where we assume  both $\kappa - \wh{\mb{E}} Z_n(\bs{\tau}^*_{\kappa,\mu}) > 0$ and $\kappa - \mb{E} Z(\bs{\tau}^*_{\kappa,\mu}) > 0$ . This convergence in probabilty is due to the consistency of $\wh{F}_{Z_n(\bs{\tau})}(z | \bs{H}_1 = \bs{h}_1)$ and dominated convergence theorem. Together, by Sluskty's theorem and the stationarity of $\bs{\tau}^*_{\kappa,\mu}$ of $S^*(\bs{\tau}, \mu)$, we have 
\begin{flalign*}
\sqrt{n} \nabla\wh{S}( {\bs{\tau}}^*_{\kappa,\mu}, \mu) \overset{d}{\to} \mathcal{N}\lt(0, \bs{C}^*\rt),
\end{flalign*}
where 
\begin{flalign*}
\bs{C}^* :=
AV\lt[\pard[\bs{\tau}] \int y \,d F_{Y^*(\bs{\tau})}(y | \bs{H}_{1} = \bs{h}_{1}) \rt]
\end{flalign*}

We have that  $\nabla^2\wh{S}(\tilde{\bs{\tau}}_{\kappa,\mu}, \mu) = \nabla^2\wh{S}(\bs{\tau}^*_{\kappa,\mu}, \mu) + o_p(1)$,  as $\tilde{\bs{\tau}}_{\kappa,\mu}$ is in between $\wh{\bs{\tau}}_{\kappa,\mu}$ and $\bs{\tau}^*_{\kappa,\mu}$ and $\wh{\bs{\tau}}_{\kappa,\mu} - \bs{\tau}^*_{\kappa,\mu} = o_p(1)$. 
Therefore, we have            
\begin{flalign*}
\bs{D}^* \triangleq & p\underset{n \to \infty}{\lim}\nabla^2\wh{S}_{\kappa} (\bs{\tau}^*_{\kappa, \mu}, \mu) \\
= & p\underset{n \to \infty}{\lim} \lt[\nabla^2 \wh{\mb{E}} Y_n(\bs{\tau}^*_{\kappa,\mu}) - \mu \frac{\nabla^2 \wh{\mb{E}} Z_n(\bs{\tau}^*_{\kappa,\mu}) \lt[ \kappa - \wh{\mb{E}} Z_n(\bs{\tau}^*_{\kappa,\mu}) \rt] + \{ \nabla \wh{\mb{E}} Z_n(\bs{\tau}^*_{\kappa,\mu}) \}^2}{  \lt\{\kappa - \wh{\mb{E}} Z_n(\bs{\tau}^*_{\kappa,\mu}) \rt\}^2}\rt] \\
= &\nabla^2 \mb{E} Y^*(\bs{\tau}^*_{\kappa,\mu}) - \mu \frac{\nabla^2 \mb{E} Z^*(\bs{\tau}^*_{\kappa,\mu}) \lt[ \kappa - \mb{E} Z^*(\bs{\tau}^*_{\kappa,\mu}) \rt] + \{ \nabla \mb{E} Z^*(\bs{\tau}^*_{\kappa,\mu}) \}^2}{  \lt\{\kappa - \mb{E} Z^*(\bs{\tau}^*_{\kappa,\mu}) \rt\}^2} \\
= & \nabla^2 {S}^* (\bs{\tau}_{\kappa,\mu}^*, \mu).
\end{flalign*}
\end{proof}
We can estimate $\bs{\Sigma}^*$ by plug in the corresponding estimators stated, and denote the estimator $\wh{\bs{\Sigma}}$, that is, $\wh{\bs{\Sigma}} = \wh{\bs{D}}^{-1}\wh{\bs{C}}\wh{\bs{D}}^{-1}$, where

\begin{flalign*}
\wh{\bs{C}} = & \wh{V}\lt\{\pard[\bs{\tau}] \int y \,d \wh{F}_{Y_n(\wh{\bs{\tau}}_{\kappa,\mu})}(y | \bs{H}_{1} = \bs{h}_{1}) \rt\} \\
= & \wh{V} \lt[\nabla \wh{\mb{E}} \lt\{Y_n(\wh{\bs{\tau}}_{\kappa,\mu}) \mid \bs{H}_1 =\bs{h_1}\rt\}\rt]
\end{flalign*}

and
\begin{gather*}                 
\begin{flalign*}
\wh{\bs{D}} =   \nabla^2\wh{S}(\wh{\bs{\tau}}_{\kappa,\mu}, \mu) = \nabla^2 \wh{\mb{E}} Y_n(\wh{\bs{\tau}}_{\kappa,\mu}) - \mu \frac{\nabla^2 \wh{\mb{E}} Z_n(\wh{\bs{\tau}}_{\kappa,\mu}) \lt[ \kappa - \wh{\mb{E}} Z_n(\wh{\bs{\tau}}_{\kappa,\mu}) \rt] + \{ \nabla \wh{\mb{E}} Z_n(\wh{\bs{\tau}}_{\kappa,\mu}) \}^2}{  \lt\{\kappa - \wh{\mb{E}} Z_n(\wh{\bs{\tau}}_{\kappa,\mu}) \rt\}^2},
\end{flalign*}
\end{gather*}

As $\wh{\bs{C}}$ , $\wh{\bs{D}}$  and $\wh{\bs{\Sigma}}$ maybe have complicated forms, bootstrap based estimators can be used for practical dataset, and Monte Carlo estimators for simulated replicates.\\

\textbf{Confidence set of $\wh{\bs{\tau}}$}\\
As  Theorem 1 that
\begin{flalign*}
	 \bs{\Sigma}^{* -\sfrac{1}{2} }(\wh{\bs{\tau}}_{\kappa,\mu} - \bs{\tau}_{\kappa,\mu}^*) \overset{d}{\to} \mathcal{N}\lt(\bs{0}, \mathbf{I}/n \rt), \text{as } n \to \infty,
\end{flalign*}
we have
\begin{flalign*}
(\wh{\bs{\tau}}_{\kappa,\mu} - \bs{\tau}_{\kappa,\mu}^*)\bs{\Sigma}^{*-1}(\wh{\bs{\tau}}_{\kappa,\mu} - \bs{\tau}_{\kappa,\mu}^*) \overset{d}{\to} \chi^2_{p+1}/n^2, \text{as } n \to \infty.
\end{flalign*}
Thus, with a consistent estimator of $\wh{\bs{\Sigma}}$, the $(1 - \alpha) \times 100 \%$ confidence set is
\begin{flalign*}
\bs{\mathcal{C}}_{1-\alpha}\lt(\bs{\tau}^*_{\kappa, \mu}\rt)= \lt\{ \bs{\tau}_{\kappa,\mu}:
(\wh{\bs{\tau}}_{\kappa,\mu} - \bs{\tau}_{\kappa,\mu})\wh{\bs{\Sigma}}^{-1}(\wh{\bs{\tau}}_{\kappa,\mu} - \bs{\tau}_{\kappa,\mu}) \le \chi^2_{p+1}( 1-\alpha )/n^2 \rt\}, \txt{ as } n \to \infty,
\end{flalign*}
where $\chi^2_{p+1}( 1-\alpha )$ is the $1-\alpha$ quantiles of a $\chi_{p+1}^2$ random variable, and $p+1$ is the dimension of $\bs{\tau}$.\\

\textbf{Projection Confidence Interval of $\mb{E}Y^*(\bs{\tau}_{\kappa, \mu}^*)$}\\
For each $\bs{\tau}_{\kappa, \mu} \in \bs{\mathcal{C}}_{1-\alpha} \lt(\bs{\tau}^*_{\kappa, \mu}\rt)$, we estimate $\mb{E} Y^*(\bs{\tau}_{\kappa, \mu})$ by $\wh{\mb{E}} Y_n(\bs{\tau}_{\kappa, \mu}) = \mean[n] \int y \,d  \wh{F}_{Y_n(\bs{\tau}_{\kappa, \mu})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})  $. Thus, assuming $\wh{F}_{Y_n(\bs{\tau}_{\kappa,\mu})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})$ is a consistent estimator of $F_{Y^*(\bs{\tau}_{\kappa,\mu})}(y | \bs{H}_{1,i} = \bs{h}_{1,i})$ , $\wh{\mb{E}} Y_n(\bs{\tau}_{\kappa, \mu})$ has a limiting distribution as 
$$\sqrt{n} \lt\{ \wh{\mb{E}}Y_n(\bs{\tau}_{\kappa, \mu})  - \mb{E} Y^*(\bs{\tau}_{\kappa, \mu}) \rt\} \sim  \mathcal{N}\lt[ 0 , AV\lt\{ \int y \,d  F_{Y^*(\bs{\tau}_{\kappa,\mu})}(y | \bs{H}_{1,i} = \bs{h}_{1,i}) \rt\}\rt].$$
For each $\bs{\tau}_{\kappa, \mu} \in \bs{\mathcal{C}}_{1-\alpha} \lt(\bs{\tau}^*_{\kappa, \mu}\rt)$, we can construct a $(1 - \eta ) \times 100 \%$ confidence interval 
\begin{flalign*}
&\bs{\mathcal{I}}_{1 -\eta} \lt\{ \mb{E}Y^*(\bs{\tau}_{\kappa, \mu})  \rt\} \\
= & \lt\{\wh{\mb{E}}Y_n(\bs{\tau}_{\kappa, \mu}) - Z_{1- \eta/2}  \wh{\sigma}_{Y^*(\bs{\tau}_{\kappa,\mu})} ,  \wh{\mb{E}}Y_n(\bs{\tau}_{\kappa, \mu}) + Z_{1 - \eta/2} \wh{\sigma}_{Y^*(\bs{\tau}_{\kappa,\mu})}  \rt\}
\end{flalign*}
where $\wh{\sigma}_{Y^*(\bs{\tau}_{\kappa,\mu})}$ is the estimator for $AV\lt\{ \int y \,d  F_{Y^*(\bs{\tau}_{\kappa,\mu})}(y | \bs{H}_{1,i} = \bs{h}_{1,i}) \rt\}$, which can also be calculated by bootstrap estimator  for practical dataset, or Monte Carlo estimator for simulated replicates.  $Z_{1- \eta/2}$ is the upper $1- \eta/2$ critical value for the standard normal distribution. Alternatively, we can also construct this confidence interval using standard methods such as percentile bootstrap. Then, we can construct the projection confidence set for $ \mb{E}Y^*\lt(\bs{\tau}_{\kappa, \mu}\rt)$ by taking the union of $\bs{\mathcal{I}}_{1 -\eta} \lt\{ \mb{E}Y^*\lt(\bs{\tau}_{\kappa, \mu}\rt)  \rt\}$ over all $\bs{\tau}_{\kappa, \mu} \in \bs{\mathcal{C}}_{1-\alpha} \lt(\bs{\tau}^*_{\kappa, \mu}\rt)$, i.e.,
$$
\bs{\mathcal{U}}_{1 - \alpha - \eta} \lt\{ \mb{E}Y^*(\bs{\tau}_{\kappa, \mu})  \rt\} = \bigcup_{\bs{\tau}_{\kappa, \mu} \in \bs{\mathcal{C}}_{1-\alpha} \lt(\bs{\tau}^*_{\kappa, \mu}\rt)} \bs{\mathcal{I}}_{1 -\eta} \lt\{ \mb{E}Y^*(\bs{\tau}_{\kappa, \mu})  \rt\}.
$$
\end{document}